{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compose: Training a model to generate music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from music21 import note, chord\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.utils import plot_model\n",
    "\n",
    "from models.RNNAttention import get_distinct, create_lookups, prepare_sequences, get_music_list, create_network\n",
    "\n",
    "import glob\n",
    "from music21 import corpus, converter\n",
    "from keras.layers import GRU, Input, Dropout, Dense, Activation, Embedding, Concatenate, Reshape\n",
    "from keras.layers import Flatten, RepeatVector, Permute, TimeDistributed\n",
    "from keras.layers import Multiply, Lambda, Softmax\n",
    "import keras.backend as K \n",
    "from keras.models import Model\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run params\n",
    "section = 'compose'\n",
    "run_id = '0006'\n",
    "music_name = 'cello'\n",
    "\n",
    "run_folder = 'run/{}/'.format(section)\n",
    "run_folder += '_'.join([run_id, music_name])\n",
    "\n",
    "\n",
    "store_folder = os.path.join(run_folder, 'store')\n",
    "data_folder = os.path.join('data', music_name)\n",
    "\n",
    "if not os.path.exists(run_folder):\n",
    "    os.mkdir(run_folder)\n",
    "    os.mkdir(os.path.join(run_folder, 'store'))\n",
    "    os.mkdir(os.path.join(run_folder, 'output'))\n",
    "    os.mkdir(os.path.join(run_folder, 'weights'))\n",
    "    os.mkdir(os.path.join(run_folder, 'viz'))\n",
    "    \n",
    "\n",
    "\n",
    "mode = 'build' # 'load' # \n",
    "\n",
    "# data params\n",
    "intervals = range(1)\n",
    "seq_len = 32\n",
    "\n",
    "# model params\n",
    "embed_size = 100\n",
    "rnn_units = 256\n",
    "use_attention = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract the notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36 files in total\n",
      "1 Parsing data\\cello\\cs1-1pre.mid\n",
      "2 Parsing data\\cello\\cs1-2all.mid\n",
      "3 Parsing data\\cello\\cs1-3cou.mid\n",
      "4 Parsing data\\cello\\cs1-4sar.mid\n",
      "5 Parsing data\\cello\\cs1-5men.mid\n",
      "6 Parsing data\\cello\\cs1-6gig.mid\n",
      "7 Parsing data\\cello\\cs2-1pre.mid\n",
      "8 Parsing data\\cello\\cs2-2all.mid\n",
      "9 Parsing data\\cello\\cs2-3cou.mid\n",
      "10 Parsing data\\cello\\cs2-4sar.mid\n",
      "11 Parsing data\\cello\\cs2-5men.mid\n",
      "12 Parsing data\\cello\\cs2-6gig.mid\n",
      "13 Parsing data\\cello\\cs3-1pre.mid\n",
      "14 Parsing data\\cello\\cs3-2all.mid\n",
      "15 Parsing data\\cello\\cs3-3cou.mid\n",
      "16 Parsing data\\cello\\cs3-4sar.mid\n",
      "17 Parsing data\\cello\\cs3-5bou.mid\n",
      "18 Parsing data\\cello\\cs3-6gig.mid\n",
      "19 Parsing data\\cello\\cs4-1pre.mid\n",
      "20 Parsing data\\cello\\cs4-2all.mid\n",
      "21 Parsing data\\cello\\cs4-3cou.mid\n",
      "22 Parsing data\\cello\\cs4-4sar.mid\n",
      "23 Parsing data\\cello\\cs4-5bou.mid\n",
      "24 Parsing data\\cello\\cs4-6gig.mid\n",
      "25 Parsing data\\cello\\cs5-1pre.mid\n",
      "26 Parsing data\\cello\\cs5-2all.mid\n",
      "27 Parsing data\\cello\\cs5-3cou.mid\n",
      "28 Parsing data\\cello\\cs5-4sar.mid\n",
      "29 Parsing data\\cello\\cs5-5gav.mid\n",
      "30 Parsing data\\cello\\cs5-6gig.mid\n",
      "31 Parsing data\\cello\\cs6-1pre.mid\n",
      "32 Parsing data\\cello\\cs6-2all.mid\n",
      "33 Parsing data\\cello\\cs6-3cou.mid\n",
      "34 Parsing data\\cello\\cs6-4sar.mid\n",
      "35 Parsing data\\cello\\cs6-5gav.mid\n",
      "36 Parsing data\\cello\\cs6-6gig.mid\n"
     ]
    }
   ],
   "source": [
    "if mode == 'build':\n",
    "    \n",
    "    music_list, parser = get_music_list(data_folder)\n",
    "    print(len(music_list), 'files in total')\n",
    "\n",
    "    notes = []\n",
    "    durations = []\n",
    "\n",
    "    for i, file in enumerate(music_list):\n",
    "        print(i+1, \"Parsing %s\" % file)\n",
    "        original_score = parser.parse(file).chordify()\n",
    "        \n",
    "\n",
    "        for interval in intervals:\n",
    "\n",
    "            score = original_score.transpose(interval)\n",
    "\n",
    "            notes.extend(['START'] * seq_len)\n",
    "            durations.extend([0]* seq_len)\n",
    "\n",
    "            for element in score.flat:\n",
    "                \n",
    "                if isinstance(element, note.Note):\n",
    "                    if element.isRest:\n",
    "                        notes.append(str(element.name))\n",
    "                        durations.append(element.duration.quarterLength)\n",
    "                    else:\n",
    "                        notes.append(str(element.nameWithOctave))\n",
    "                        durations.append(element.duration.quarterLength)\n",
    "\n",
    "                if isinstance(element, chord.Chord):\n",
    "                    notes.append('.'.join(n.nameWithOctave for n in element.pitches))\n",
    "                    durations.append(element.duration.quarterLength)\n",
    "\n",
    "    with open(os.path.join(store_folder, 'notes'), 'wb') as f:\n",
    "        pickle.dump(notes, f) #['G2', 'D3', 'B3', 'A3', 'B3', 'D3', 'B3', 'D3', 'G2',...]\n",
    "    with open(os.path.join(store_folder, 'durations'), 'wb') as f:\n",
    "        pickle.dump(durations, f) \n",
    "else:\n",
    "    with open(os.path.join(store_folder, 'notes'), 'rb') as f:\n",
    "        notes = pickle.load(f) #['G2', 'D3', 'B3', 'A3', 'B3', 'D3', 'B3', 'D3', 'G2',...]\n",
    "    with open(os.path.join(store_folder, 'durations'), 'rb') as f:\n",
    "        durations = pickle.load(f) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the lookup tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the distinct sets of notes and durations\n",
    "note_names, n_notes = get_distinct(notes)\n",
    "duration_names, n_durations = get_distinct(durations)\n",
    "distincts = [note_names, n_notes, duration_names, n_durations]\n",
    "\n",
    "with open(os.path.join(store_folder, 'distincts'), 'wb') as f:\n",
    "    pickle.dump(distincts, f)\n",
    "\n",
    "# make the lookup dictionaries for notes and dictionaries and save\n",
    "note_to_int, int_to_note = create_lookups(note_names)\n",
    "duration_to_int, int_to_duration = create_lookups(duration_names)\n",
    "lookups = [note_to_int, int_to_note, duration_to_int, int_to_duration]\n",
    "\n",
    "with open(os.path.join(store_folder, 'lookups'), 'wb') as f:\n",
    "    pickle.dump(lookups, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "note_to_int\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'A2': 0,\n",
       " 'A2.A3': 1,\n",
       " 'A2.B2': 2,\n",
       " 'A2.C3': 3,\n",
       " 'A2.C3.D3.E3': 4,\n",
       " 'A2.D3': 5,\n",
       " 'A2.E-3': 6,\n",
       " 'A2.E3': 7,\n",
       " 'A2.E3.A3': 8,\n",
       " 'A2.E3.C#4': 9,\n",
       " 'A2.E3.C#4.A4': 10,\n",
       " 'A2.E3.C#4.E4': 11,\n",
       " 'A2.E3.C#4.G#4': 12,\n",
       " 'A2.E3.C4': 13,\n",
       " 'A2.E3.D4': 14,\n",
       " 'A2.F#3': 15,\n",
       " 'A2.F#3.C4': 16,\n",
       " 'A2.F#3.D4': 17,\n",
       " 'A2.F#3.D4.A4': 18,\n",
       " 'A2.F#3.D4.E4': 19,\n",
       " 'A2.F#3.D4.F#4': 20,\n",
       " 'A2.F#4': 21,\n",
       " 'A2.F3': 22,\n",
       " 'A2.F3.C4': 23,\n",
       " 'A2.F3.D4': 24,\n",
       " 'A2.F3.D4.A4': 25,\n",
       " 'A2.G3': 26,\n",
       " 'A2.G3.C#4': 27,\n",
       " 'A2.G3.D4': 28,\n",
       " 'A3': 29,\n",
       " 'A3.B-3': 30,\n",
       " 'A3.B3': 31,\n",
       " 'A3.B3.A4': 32,\n",
       " 'A3.B3.C#4': 33,\n",
       " 'A3.B3.C4': 34,\n",
       " 'A3.B3.F#4.G4': 35,\n",
       " 'A3.B3.G4': 36,\n",
       " 'A3.C#4': 37,\n",
       " 'A3.C#4.E4': 38,\n",
       " 'A3.C4': 39,\n",
       " 'A3.D4': 40,\n",
       " 'A3.D4.E4': 41,\n",
       " 'A3.D4.F#4': 42,\n",
       " 'A3.E4': 43,\n",
       " 'A3.E4.F#4': 44,\n",
       " 'A3.E4.F#4.G4': 45,\n",
       " 'A3.E4.G4': 46,\n",
       " 'A3.F#4': 47,\n",
       " 'A3.F#4.G4': 48,\n",
       " 'A3.F4': 49,\n",
       " 'A3.G#4.A4': 50,\n",
       " 'A3.G4': 51,\n",
       " 'A4': 52,\n",
       " 'A4.B4': 53,\n",
       " 'B-2': 54,\n",
       " 'B-2.A3': 55,\n",
       " 'B-2.B-3': 56,\n",
       " 'B-2.D3': 57,\n",
       " 'B-2.D3.A3': 58,\n",
       " 'B-2.D3.E-3.G#3': 59,\n",
       " 'B-2.D3.G#3': 60,\n",
       " 'B-2.E-3': 61,\n",
       " 'B-2.E3': 62,\n",
       " 'B-2.E3.D4': 63,\n",
       " 'B-2.F#3.C#4.E4': 64,\n",
       " 'B-2.F3': 65,\n",
       " 'B-2.F3.C4': 66,\n",
       " 'B-2.F3.D4': 67,\n",
       " 'B-2.F3.E-4': 68,\n",
       " 'B-2.G#3': 69,\n",
       " 'B-2.G3': 70,\n",
       " 'B-2.G3.D4': 71,\n",
       " 'B-3': 72,\n",
       " 'B-3.B-4.B4.C#5.D5': 73,\n",
       " 'B-3.C4': 74,\n",
       " 'B-3.E4': 75,\n",
       " 'B-4': 76,\n",
       " 'B-4.B4.C#5.D5': 77,\n",
       " 'B2': 78,\n",
       " 'B2.A3': 79,\n",
       " 'B2.C#3': 80,\n",
       " 'B2.C3': 81,\n",
       " 'B2.D3': 82,\n",
       " 'B2.D3.B3.F#4': 83,\n",
       " 'B2.E-3': 84,\n",
       " 'B2.E3.D4': 85,\n",
       " 'B2.E3.E4': 86,\n",
       " 'B2.F#3': 87,\n",
       " 'B2.F#3.A3.B3': 88,\n",
       " 'B2.F#3.A3.B3.C4': 89,\n",
       " 'B2.F#3.B3': 90,\n",
       " 'B2.F#3.C#4.D4.E4': 91,\n",
       " 'B2.F#3.D4': 92,\n",
       " 'B2.F#3.E-4': 93,\n",
       " 'B2.F#3.E-4.A4': 94,\n",
       " 'B2.F3': 95,\n",
       " 'B2.G#3': 96,\n",
       " 'B2.G#3.D4': 97,\n",
       " 'B2.G3': 98,\n",
       " 'B2.G3.B3.C4.D4': 99,\n",
       " 'B3': 100,\n",
       " 'B3.C#4': 101,\n",
       " 'B3.C#4.D4': 102,\n",
       " 'B3.C#4.D4.E4': 103,\n",
       " 'B3.C#4.E4': 104,\n",
       " 'B3.C#4.F#4.G#4.A4': 105,\n",
       " 'B3.C4': 106,\n",
       " 'B3.D4': 107,\n",
       " 'B3.D4.E4': 108,\n",
       " 'B3.D4.F#4': 109,\n",
       " 'B3.E4': 110,\n",
       " 'B3.F#4': 111,\n",
       " 'B3.G#4.A4': 112,\n",
       " 'B3.G4': 113,\n",
       " 'B3.G4.A4': 114,\n",
       " 'B4': 115,\n",
       " 'C#2': 116,\n",
       " 'C#2.B-2.F3': 117,\n",
       " 'C#2.B-2.G3': 118,\n",
       " 'C#3': 119,\n",
       " 'C#3.D3': 120,\n",
       " 'C#3.E3.A3': 121,\n",
       " 'C#3.E3.B3.E4': 122,\n",
       " 'C#3.G3': 123,\n",
       " 'C#3.G3.A3': 124,\n",
       " 'C#3.G3.B-3': 125,\n",
       " 'C#4': 126,\n",
       " 'C#4.A4': 127,\n",
       " 'C#4.D4': 128,\n",
       " 'C#4.D4.E4': 129,\n",
       " 'C#4.D4.E4.F#4.G4': 130,\n",
       " 'C#4.D4.F#4': 131,\n",
       " 'C#4.E4': 132,\n",
       " 'C#4.F#4': 133,\n",
       " 'C#5': 134,\n",
       " 'C2': 135,\n",
       " 'C2.A2.E-3': 136,\n",
       " 'C2.A2.F#3': 137,\n",
       " 'C2.A2.F#3.D4': 138,\n",
       " 'C2.A2.F3.A3': 139,\n",
       " 'C2.A2.G3.A3': 140,\n",
       " 'C2.B-2': 141,\n",
       " 'C2.B-2.E3': 142,\n",
       " 'C2.B2.F3.G#3': 143,\n",
       " 'C2.C3': 144,\n",
       " 'C2.D3.E3': 145,\n",
       " 'C2.E-3': 146,\n",
       " 'C2.E-3.G3': 147,\n",
       " 'C2.E3.G3': 148,\n",
       " 'C2.G#2': 149,\n",
       " 'C2.G#2.D3.B3': 150,\n",
       " 'C2.G2': 151,\n",
       " 'C2.G2.D3': 152,\n",
       " 'C2.G2.E-3': 153,\n",
       " 'C2.G2.E-3.B-3': 154,\n",
       " 'C2.G2.E-3.C4': 155,\n",
       " 'C2.G2.E3': 156,\n",
       " 'C2.G2.E3.B-3': 157,\n",
       " 'C2.G2.E3.C4': 158,\n",
       " 'C2.G2.F3': 159,\n",
       " 'C2.G2.F3.C4': 160,\n",
       " 'C3': 161,\n",
       " 'C3.A3': 162,\n",
       " 'C3.A3.E-4': 163,\n",
       " 'C3.B-3': 164,\n",
       " 'C3.D3': 165,\n",
       " 'C3.E-3': 166,\n",
       " 'C3.E3': 167,\n",
       " 'C3.E3.A3': 168,\n",
       " 'C3.E3.B-3': 169,\n",
       " 'C3.E3.B3': 170,\n",
       " 'C3.E3.E4': 171,\n",
       " 'C3.E3.F#4': 172,\n",
       " 'C3.F#3': 173,\n",
       " 'C3.F3': 174,\n",
       " 'C3.G#3': 175,\n",
       " 'C3.G#3.E-4': 176,\n",
       " 'C3.G3': 177,\n",
       " 'C3.G3.A3': 178,\n",
       " 'C3.G3.B-3': 179,\n",
       " 'C3.G3.C4': 180,\n",
       " 'C3.G3.E-4': 181,\n",
       " 'C4': 182,\n",
       " 'C4.D4': 183,\n",
       " 'C4.E4': 184,\n",
       " 'C4.F#4': 185,\n",
       " 'C5': 186,\n",
       " 'D2': 187,\n",
       " 'D2.A2.D3': 188,\n",
       " 'D2.A2.F#3': 189,\n",
       " 'D2.A2.F#3.C#4': 190,\n",
       " 'D2.A2.F#3.C4': 191,\n",
       " 'D2.A2.F#3.D4': 192,\n",
       " 'D2.A2.F3': 193,\n",
       " 'D2.A2.F3.A3': 194,\n",
       " 'D2.A2.F3.D4': 195,\n",
       " 'D2.B-2.F3.G#3': 196,\n",
       " 'D2.B-2.G#3': 197,\n",
       " 'D2.B-2.G3.C4': 198,\n",
       " 'D2.B-2.G3.D4': 199,\n",
       " 'D2.B2': 200,\n",
       " 'D2.B2.F3': 201,\n",
       " 'D2.B2.G3': 202,\n",
       " 'D2.C3.F#3.E-4': 203,\n",
       " 'D2.E-3': 204,\n",
       " 'D2.G2.F3.B3': 205,\n",
       " 'D3': 206,\n",
       " 'D3.A3': 207,\n",
       " 'D3.A3.F#4': 208,\n",
       " 'D3.A3.G4': 209,\n",
       " 'D3.A4': 210,\n",
       " 'D3.B-3': 211,\n",
       " 'D3.B3': 212,\n",
       " 'D3.B3.G4': 213,\n",
       " 'D3.C#4': 214,\n",
       " 'D3.C#4.E4': 215,\n",
       " 'D3.C#4.F#4': 216,\n",
       " 'D3.C4': 217,\n",
       " 'D3.C4.F#4': 218,\n",
       " 'D3.D4': 219,\n",
       " 'D3.E-3': 220,\n",
       " 'D3.E-4': 221,\n",
       " 'D3.E3': 222,\n",
       " 'D3.E3.F#3': 223,\n",
       " 'D3.E3.F#3.A3': 224,\n",
       " 'D3.E3.F#3.F#4.G4': 225,\n",
       " 'D3.E3.F#4.G4': 226,\n",
       " 'D3.E4': 227,\n",
       " 'D3.F#3': 228,\n",
       " 'D3.F#4': 229,\n",
       " 'D3.F3': 230,\n",
       " 'D3.F3.A3': 231,\n",
       " 'D3.F4': 232,\n",
       " 'D3.G#3': 233,\n",
       " 'D3.G3': 234,\n",
       " 'D3.G3.A3': 235,\n",
       " 'D3.G3.G#3': 236,\n",
       " 'D3.G4': 237,\n",
       " 'D4': 238,\n",
       " 'D4.A4': 239,\n",
       " 'D4.B4': 240,\n",
       " 'D4.C5': 241,\n",
       " 'D4.E-4': 242,\n",
       " 'D4.E4': 243,\n",
       " 'D4.E4.F#4': 244,\n",
       " 'D4.E4.F#4.G4': 245,\n",
       " 'D4.F#4': 246,\n",
       " 'D4.G#4': 247,\n",
       " 'D5': 248,\n",
       " 'E-2': 249,\n",
       " 'E-2.B-2.E-3': 250,\n",
       " 'E-2.B-2.E-3.G3': 251,\n",
       " 'E-2.B-2.F3': 252,\n",
       " 'E-2.B-2.G#3': 253,\n",
       " 'E-2.B-2.G3': 254,\n",
       " 'E-2.B-2.G3.E-4': 255,\n",
       " 'E-2.C3': 256,\n",
       " 'E-2.G2': 257,\n",
       " 'E-2.G2.D3': 258,\n",
       " 'E-2.G2.G3.A3': 259,\n",
       " 'E-2.G3': 260,\n",
       " 'E-3': 261,\n",
       " 'E-3.A3': 262,\n",
       " 'E-3.B-3': 263,\n",
       " 'E-3.C#4': 264,\n",
       " 'E-3.C4': 265,\n",
       " 'E-3.C4.F#4': 266,\n",
       " 'E-3.D4': 267,\n",
       " 'E-3.F#3': 268,\n",
       " 'E-3.F3': 269,\n",
       " 'E-3.F3.G3': 270,\n",
       " 'E-3.G#3': 271,\n",
       " 'E-3.G3': 272,\n",
       " 'E-4': 273,\n",
       " 'E-4.E4': 274,\n",
       " 'E-4.F4': 275,\n",
       " 'E-5': 276,\n",
       " 'E2': 277,\n",
       " 'E2.B2.G#3.D4': 278,\n",
       " 'E2.B2.G3': 279,\n",
       " 'E2.C3.G3': 280,\n",
       " 'E2.C3.G3.B-3': 281,\n",
       " 'E2.E3.G3': 282,\n",
       " 'E2.G2': 283,\n",
       " 'E3': 284,\n",
       " 'E3.A3': 285,\n",
       " 'E3.B-3': 286,\n",
       " 'E3.B3': 287,\n",
       " 'E3.B3.A4': 288,\n",
       " 'E3.B3.C#4.D4.E4.F#4.G4': 289,\n",
       " 'E3.B3.F#4': 290,\n",
       " 'E3.B3.F#4.G4': 291,\n",
       " 'E3.B3.G4': 292,\n",
       " 'E3.C#4': 293,\n",
       " 'E3.C#4.D4.E4': 294,\n",
       " 'E3.C#4.E4': 295,\n",
       " 'E3.C#4.G4': 296,\n",
       " 'E3.C4': 297,\n",
       " 'E3.D4': 298,\n",
       " 'E3.D4.E4': 299,\n",
       " 'E3.D4.G#4': 300,\n",
       " 'E3.D4.G#4.A4': 301,\n",
       " 'E3.F#3': 302,\n",
       " 'E3.F3': 303,\n",
       " 'E3.G3': 304,\n",
       " 'E4': 305,\n",
       " 'E4.F#4': 306,\n",
       " 'E4.F#4.G4': 307,\n",
       " 'E4.F#4.G4.B4': 308,\n",
       " 'E4.G#4': 309,\n",
       " 'E4.G4': 310,\n",
       " 'E5': 311,\n",
       " 'F#2': 312,\n",
       " 'F#2.A2.D3.A3': 313,\n",
       " 'F#2.C3.E-3.C4': 314,\n",
       " 'F#2.E3.C#4.E4': 315,\n",
       " 'F#2.G2': 316,\n",
       " 'F#3': 317,\n",
       " 'F#3.A3': 318,\n",
       " 'F#3.A3.E4': 319,\n",
       " 'F#3.B3': 320,\n",
       " 'F#3.B3.A4': 321,\n",
       " 'F#3.B3.C#4.D4': 322,\n",
       " 'F#3.B3.C#4.G#4.A4': 323,\n",
       " 'F#3.C#4': 324,\n",
       " 'F#3.C#4.A4': 325,\n",
       " 'F#3.C#4.E4': 326,\n",
       " 'F#3.C4': 327,\n",
       " 'F#3.D4': 328,\n",
       " 'F#3.D4.A4': 329,\n",
       " 'F#3.G#3': 330,\n",
       " 'F#3.G3': 331,\n",
       " 'F#3.G3.A3': 332,\n",
       " 'F#4': 333,\n",
       " 'F#4.A4': 334,\n",
       " 'F#4.D5': 335,\n",
       " 'F#4.G4': 336,\n",
       " 'F#4.G4.A4': 337,\n",
       " 'F#5': 338,\n",
       " 'F2': 339,\n",
       " 'F2.A2': 340,\n",
       " 'F2.A2.D3': 341,\n",
       " 'F2.A2.D3.A3': 342,\n",
       " 'F2.A2.E3': 343,\n",
       " 'F2.A3': 344,\n",
       " 'F2.B-2': 345,\n",
       " 'F2.B2.G3': 346,\n",
       " 'F2.C3': 347,\n",
       " 'F2.C3.D3': 348,\n",
       " 'F2.C3.E-3': 349,\n",
       " 'F2.C3.G#3': 350,\n",
       " 'F2.D3.G#3': 351,\n",
       " 'F2.G#2.D3': 352,\n",
       " 'F2.G#2.E-3': 353,\n",
       " 'F2.G2.D3.B3': 354,\n",
       " 'F3': 355,\n",
       " 'F3.A3': 356,\n",
       " 'F3.B-3': 357,\n",
       " 'F3.B3': 358,\n",
       " 'F3.C#4.D4': 359,\n",
       " 'F3.C4': 360,\n",
       " 'F3.D4': 361,\n",
       " 'F3.E4': 362,\n",
       " 'F3.G#3': 363,\n",
       " 'F3.G3': 364,\n",
       " 'F4': 365,\n",
       " 'F4.F#4': 366,\n",
       " 'G#2': 367,\n",
       " 'G#2.B-2': 368,\n",
       " 'G#2.C3.D3': 369,\n",
       " 'G#2.D3': 370,\n",
       " 'G#2.D3.B3': 371,\n",
       " 'G#2.E-3': 372,\n",
       " 'G#2.E-3.B-3': 373,\n",
       " 'G#2.E-3.C#4': 374,\n",
       " 'G#2.E-3.C4': 375,\n",
       " 'G#2.E3.B3': 376,\n",
       " 'G#2.E3.C#4': 377,\n",
       " 'G#2.E3.D4': 378,\n",
       " 'G#2.E3.D4.B4': 379,\n",
       " 'G#2.F#4': 380,\n",
       " 'G#2.F3': 381,\n",
       " 'G#2.F3.B3': 382,\n",
       " 'G#2.F3.C4': 383,\n",
       " 'G#2.F3.D4': 384,\n",
       " 'G#2.F3.E-4': 385,\n",
       " 'G#2.G3': 386,\n",
       " 'G#3': 387,\n",
       " 'G#3.A3': 388,\n",
       " 'G#3.B-3': 389,\n",
       " 'G#3.B3': 390,\n",
       " 'G#3.D4': 391,\n",
       " 'G#3.D4.E4': 392,\n",
       " 'G#3.D4.F#4': 393,\n",
       " 'G#3.E4': 394,\n",
       " 'G#3.F4': 395,\n",
       " 'G#3.G#4.A4': 396,\n",
       " 'G#4': 397,\n",
       " 'G#4.A4': 398,\n",
       " 'G#4.B4': 399,\n",
       " 'G2': 400,\n",
       " 'G2.A3': 401,\n",
       " 'G2.B-3': 402,\n",
       " 'G2.B2': 403,\n",
       " 'G2.B3': 404,\n",
       " 'G2.B3.D4': 405,\n",
       " 'G2.B3.G4': 406,\n",
       " 'G2.C4': 407,\n",
       " 'G2.D3': 408,\n",
       " 'G2.D3.A3': 409,\n",
       " 'G2.D3.A3.G4': 410,\n",
       " 'G2.D3.B-3': 411,\n",
       " 'G2.D3.B3': 412,\n",
       " 'G2.D3.B3.A4': 413,\n",
       " 'G2.D3.B3.F#4': 414,\n",
       " 'G2.D3.C#4': 415,\n",
       " 'G2.D3.C4': 416,\n",
       " 'G2.D3.C4.G4': 417,\n",
       " 'G2.D3.D4': 418,\n",
       " 'G2.D3.G3': 419,\n",
       " 'G2.E-3': 420,\n",
       " 'G2.E-3.B-3': 421,\n",
       " 'G2.E3': 422,\n",
       " 'G2.E3.A3.C#4.A4': 423,\n",
       " 'G2.E3.B3': 424,\n",
       " 'G2.E3.C#4': 425,\n",
       " 'G2.E3.C#4.A4': 426,\n",
       " 'G2.E3.C4': 427,\n",
       " 'G2.E3.D4': 428,\n",
       " 'G2.E3.F3': 429,\n",
       " 'G2.F#3': 430,\n",
       " 'G2.F#3.D4': 431,\n",
       " 'G2.F#3.E-4': 432,\n",
       " 'G2.F3': 433,\n",
       " 'G2.F3.B-3': 434,\n",
       " 'G2.F3.B3': 435,\n",
       " 'G2.F3.C4': 436,\n",
       " 'G2.F3.D4': 437,\n",
       " 'G2.F3.G3': 438,\n",
       " 'G2.G#3': 439,\n",
       " 'G2.G3': 440,\n",
       " 'G2.G3.B3.C#4': 441,\n",
       " 'G2.G3.B3.E4': 442,\n",
       " 'G2.G3.E4': 443,\n",
       " 'G3': 444,\n",
       " 'G3.A3': 445,\n",
       " 'G3.B-3': 446,\n",
       " 'G3.B3': 447,\n",
       " 'G3.B3.B4': 448,\n",
       " 'G3.B3.E4': 449,\n",
       " 'G3.B3.F#4': 450,\n",
       " 'G3.C#4': 451,\n",
       " 'G3.C4': 452,\n",
       " 'G3.D4': 453,\n",
       " 'G3.D4.B4': 454,\n",
       " 'G3.E-4': 455,\n",
       " 'G3.E4': 456,\n",
       " 'G4': 457,\n",
       " 'G4.A4': 458,\n",
       " 'G5': 459,\n",
       " 'START': 460}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('\\nnote_to_int')\n",
    "note_to_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "duration_to_int\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 0,\n",
       " Fraction(1, 12): 1,\n",
       " Fraction(1, 6): 2,\n",
       " 0.25: 3,\n",
       " Fraction(1, 3): 4,\n",
       " Fraction(5, 12): 5,\n",
       " 0.5: 6,\n",
       " Fraction(2, 3): 7,\n",
       " 0.75: 8,\n",
       " 1.0: 9,\n",
       " 1.25: 10,\n",
       " Fraction(4, 3): 11,\n",
       " 1.5: 12,\n",
       " 1.75: 13,\n",
       " 2.0: 14,\n",
       " 2.25: 15,\n",
       " 2.5: 16,\n",
       " 3.0: 17,\n",
       " 4.0: 18}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('\\nduration_to_int')\n",
    "duration_to_int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the sequences used by the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import GRU\n",
    "\n",
    "def create_network(n_notes, n_durations, embed_size = 100, rnn_units = 256, use_attention = False):\n",
    "    \"\"\" create the structure of the neural network \"\"\"\n",
    "\n",
    "    notes_in = Input(shape = (None,))\n",
    "    durations_in = Input(shape = (None,))\n",
    "\n",
    "    x1 = Embedding(n_notes, embed_size)(notes_in)\n",
    "    x2 = Embedding(n_durations, embed_size)(durations_in) \n",
    "\n",
    "    x = Concatenate()([x1,x2])\n",
    "\n",
    "    #x = LSTM(rnn_units, return_sequences=True)(x)\n",
    "    x = GRU(rnn_units, return_sequences=True)(x)\n",
    "    # x = Dropout(0.2)(x)\n",
    "\n",
    "    if use_attention:\n",
    "\n",
    "        #x = LSTM(rnn_units, return_sequences=True)(x)\n",
    "        x = GRU(rnn_units, return_sequences=True)(x)\n",
    "        # x = Dropout(0.2)(x)\n",
    "\n",
    "        e = Dense(1, activation='tanh')(x)\n",
    "        e = Reshape([-1])(e)\n",
    "        alpha = Activation('softmax')(e)\n",
    "\n",
    "        alpha_repeated = Permute([2, 1])(RepeatVector(rnn_units)(alpha))\n",
    "\n",
    "        c = Multiply()([x, alpha_repeated])\n",
    "        c = Lambda(lambda xin: K.sum(xin, axis=1), output_shape=(rnn_units,))(c)\n",
    "    \n",
    "    else:\n",
    "        #c = LSTM(rnn_units)(x)\n",
    "        c = GRU(rnn_units)(x)\n",
    "        # c = Dropout(0.2)(c)\n",
    "                                    \n",
    "    notes_out = Dense(n_notes, activation = 'softmax', name = 'pitch')(c)\n",
    "    durations_out = Dense(n_durations, activation = 'softmax', name = 'duration')(c)\n",
    "   \n",
    "    model = Model([notes_in, durations_in], [notes_out, durations_out])\n",
    "    \n",
    "\n",
    "    if use_attention:\n",
    "        att_model = Model([notes_in, durations_in], alpha)\n",
    "    else:\n",
    "        att_model = None\n",
    "\n",
    "\n",
    "    opti = RMSprop(lr = 0.001)\n",
    "    model.compile(loss=['categorical_crossentropy', 'categorical_crossentropy'], optimizer=opti)\n",
    "\n",
    "    return model, att_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_input, network_output = prepare_sequences(notes, durations, lookups, distincts, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pitch input\n",
      "[460 460 460 460 460 460 460 460 460 460 460 460 460 460 460 460 460 460\n",
      " 460 460 460 460 460 460 460 460 460 460 460 460 460 460]\n",
      "duration input\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "pitch output\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n",
      "duration output\n",
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print('pitch input')\n",
    "print(network_input[0][0])\n",
    "print('duration input')\n",
    "print(network_input[1][0])\n",
    "print('pitch output')\n",
    "print(network_output[0][0])\n",
    "print('duration output')\n",
    "print(network_output[1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the structure of the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 100)    46100       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, None, 100)    1900        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, None, 200)    0           embedding_1[0][0]                \n",
      "                                                                 embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "gru_1 (GRU)                     (None, None, 256)    350976      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "gru_2 (GRU)                     (None, None, 256)    393984      gru_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 1)      257         gru_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, None)         0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, None)         0           reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_1 (RepeatVector)  (None, 256, None)    0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "permute_1 (Permute)             (None, None, 256)    0           repeat_vector_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, None, 256)    0           gru_2[0][0]                      \n",
      "                                                                 permute_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 256)          0           multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pitch (Dense)                   (None, 461)          118477      lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "duration (Dense)                (None, 19)           4883        lambda_1[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 916,577\n",
      "Trainable params: 916,577\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model, att_model = create_network(n_notes, n_durations, embed_size, rnn_units, use_attention)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Failed to import `pydot`. Please install `pydot`. For example with `pip install pydot`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-03d2bd004a93>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplot_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_folder\u001b[0m \u001b[1;33m,\u001b[0m\u001b[1;34m'viz/model.png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_shapes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_layer_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36mplot_model\u001b[1;34m(model, to_file, show_shapes, show_layer_names, rankdir, expand_nested, dpi)\u001b[0m\n\u001b[0;32m    238\u001b[0m     \"\"\"\n\u001b[0;32m    239\u001b[0m     dot = model_to_dot(model, show_shapes, show_layer_names, rankdir,\n\u001b[1;32m--> 240\u001b[1;33m                        expand_nested, dpi)\n\u001b[0m\u001b[0;32m    241\u001b[0m     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextension\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mextension\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36mmodel_to_dot\u001b[1;34m(model, show_shapes, show_layer_names, rankdir, expand_nested, dpi, subgraph)\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m     \u001b[0m_check_pydot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msubgraph\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[0mdot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCluster\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstyle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'dashed'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgraph_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpydot\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         raise ImportError(\n\u001b[1;32m---> 22\u001b[1;33m             \u001b[1;34m'Failed to import `pydot`. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m             \u001b[1;34m'Please install `pydot`. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m             'For example with `pip install pydot`.')\n",
      "\u001b[1;31mImportError\u001b[0m: Failed to import `pydot`. Please install `pydot`. For example with `pip install pydot`."
     ]
    }
   ],
   "source": [
    "plot_model(model, to_file=os.path.join(run_folder ,'viz/model.png'), show_shapes = True, show_layer_names = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_folder = os.path.join(run_folder, 'weights')\n",
    "# model.load_weights(os.path.join(weights_folder, \"weights.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 23024 samples, validate on 5757 samples\n",
      "Epoch 1/100\n",
      "23024/23024 [==============================] - 86s 4ms/step - loss: 4.0327 - pitch_loss: 3.2905 - duration_loss: 0.7425 - val_loss: 6.0284 - val_pitch_loss: 5.2540 - val_duration_loss: 0.7741\n",
      "Epoch 2/100\n",
      "23024/23024 [==============================] - 83s 4ms/step - loss: 3.6579 - pitch_loss: 3.0718 - duration_loss: 0.5858 - val_loss: 6.0587 - val_pitch_loss: 5.2892 - val_duration_loss: 0.7695\n",
      "Epoch 3/100\n",
      "23024/23024 [==============================] - 82s 4ms/step - loss: 3.5098 - pitch_loss: 2.9634 - duration_loss: 0.5462 - val_loss: 5.9664 - val_pitch_loss: 5.1832 - val_duration_loss: 0.7830\n",
      "Epoch 4/100\n",
      "23024/23024 [==============================] - 82s 4ms/step - loss: 3.3875 - pitch_loss: 2.8662 - duration_loss: 0.5214 - val_loss: 5.8219 - val_pitch_loss: 5.0430 - val_duration_loss: 0.7785\n",
      "Epoch 5/100\n",
      "23024/23024 [==============================] - 86s 4ms/step - loss: 3.2724 - pitch_loss: 2.7786 - duration_loss: 0.4931 - val_loss: 6.0418 - val_pitch_loss: 5.1212 - val_duration_loss: 0.9202\n",
      "Epoch 6/100\n",
      "23024/23024 [==============================] - 85s 4ms/step - loss: 3.1641 - pitch_loss: 2.6924 - duration_loss: 0.4715 - val_loss: 6.1283 - val_pitch_loss: 5.3638 - val_duration_loss: 0.7640\n",
      "Epoch 7/100\n",
      "23024/23024 [==============================] - 85s 4ms/step - loss: 3.0549 - pitch_loss: 2.6065 - duration_loss: 0.4479 - val_loss: 6.5026 - val_pitch_loss: 5.5356 - val_duration_loss: 0.9664\n",
      "Epoch 8/100\n",
      "23024/23024 [==============================] - 85s 4ms/step - loss: 2.9546 - pitch_loss: 2.5302 - duration_loss: 0.4241 - val_loss: 6.3529 - val_pitch_loss: 5.4769 - val_duration_loss: 0.8754\n",
      "Epoch 9/100\n",
      "23024/23024 [==============================] - 80s 3ms/step - loss: 2.8480 - pitch_loss: 2.4437 - duration_loss: 0.4041 - val_loss: 6.6225 - val_pitch_loss: 5.5790 - val_duration_loss: 1.0431\n",
      "Epoch 10/100\n",
      "23024/23024 [==============================] - 91s 4ms/step - loss: 2.7355 - pitch_loss: 2.3558 - duration_loss: 0.3790 - val_loss: 6.5449 - val_pitch_loss: 5.4940 - val_duration_loss: 1.0504\n",
      "Epoch 11/100\n",
      "23024/23024 [==============================] - 94s 4ms/step - loss: 2.6173 - pitch_loss: 2.2682 - duration_loss: 0.3498 - val_loss: 6.7692 - val_pitch_loss: 5.7609 - val_duration_loss: 1.0078\n",
      "Epoch 12/100\n",
      "23024/23024 [==============================] - 79s 3ms/step - loss: 2.4964 - pitch_loss: 2.1677 - duration_loss: 0.3283 - val_loss: 7.2099 - val_pitch_loss: 5.9588 - val_duration_loss: 1.2501\n",
      "Epoch 13/100\n",
      "23024/23024 [==============================] - 80s 3ms/step - loss: 2.3693 - pitch_loss: 2.0705 - duration_loss: 0.2983 - val_loss: 7.2064 - val_pitch_loss: 6.0419 - val_duration_loss: 1.1636\n",
      "Epoch 14/100\n",
      "23024/23024 [==============================] - 83s 4ms/step - loss: 2.2295 - pitch_loss: 1.9562 - duration_loss: 0.2728 - val_loss: 7.3816 - val_pitch_loss: 6.1293 - val_duration_loss: 1.2517\n",
      "Epoch 15/100\n",
      "23024/23024 [==============================] - 87s 4ms/step - loss: 2.0770 - pitch_loss: 1.8323 - duration_loss: 0.2452 - val_loss: 7.2713 - val_pitch_loss: 5.9949 - val_duration_loss: 1.2757\n",
      "Epoch 16/100\n",
      "23024/23024 [==============================] - 90s 4ms/step - loss: 1.9361 - pitch_loss: 1.7124 - duration_loss: 0.2239 - val_loss: 7.6990 - val_pitch_loss: 6.2950 - val_duration_loss: 1.4033\n",
      "Epoch 17/100\n",
      "23024/23024 [==============================] - 78s 3ms/step - loss: 1.7945 - pitch_loss: 1.5982 - duration_loss: 0.1964 - val_loss: 7.9531 - val_pitch_loss: 6.5090 - val_duration_loss: 1.4433\n",
      "Epoch 18/100\n",
      "23024/23024 [==============================] - 81s 4ms/step - loss: 1.6701 - pitch_loss: 1.4907 - duration_loss: 0.1789 - val_loss: 8.4179 - val_pitch_loss: 6.9340 - val_duration_loss: 1.4830\n",
      "Epoch 19/100\n",
      "23024/23024 [==============================] - 78s 3ms/step - loss: 1.5654 - pitch_loss: 1.4010 - duration_loss: 0.1644 - val_loss: 8.6969 - val_pitch_loss: 7.1286 - val_duration_loss: 1.5676\n",
      "Epoch 20/100\n",
      "23024/23024 [==============================] - 78s 3ms/step - loss: 1.4670 - pitch_loss: 1.3203 - duration_loss: 0.1469 - val_loss: 9.2074 - val_pitch_loss: 7.5239 - val_duration_loss: 1.6825\n",
      "Epoch 21/100\n",
      "23024/23024 [==============================] - 78s 3ms/step - loss: 1.3798 - pitch_loss: 1.2445 - duration_loss: 0.1350 - val_loss: 9.4094 - val_pitch_loss: 7.5991 - val_duration_loss: 1.8096\n",
      "Epoch 22/100\n",
      "23024/23024 [==============================] - 78s 3ms/step - loss: 1.3039 - pitch_loss: 1.1783 - duration_loss: 0.1259 - val_loss: 9.7007 - val_pitch_loss: 8.0256 - val_duration_loss: 1.6744\n",
      "Epoch 23/100\n",
      "23024/23024 [==============================] - 78s 3ms/step - loss: 1.2361 - pitch_loss: 1.1194 - duration_loss: 0.1170 - val_loss: 9.9501 - val_pitch_loss: 8.1613 - val_duration_loss: 1.7880\n",
      "Epoch 24/100\n",
      "23024/23024 [==============================] - 78s 3ms/step - loss: 1.1756 - pitch_loss: 1.0650 - duration_loss: 0.1110 - val_loss: 10.1690 - val_pitch_loss: 8.3202 - val_duration_loss: 1.8481\n",
      "Epoch 25/100\n",
      "23024/23024 [==============================] - 78s 3ms/step - loss: 1.1327 - pitch_loss: 1.0245 - duration_loss: 0.1079 - val_loss: 10.4068 - val_pitch_loss: 8.4349 - val_duration_loss: 1.9708\n",
      "Epoch 26/100\n",
      "23024/23024 [==============================] - 83s 4ms/step - loss: 1.0914 - pitch_loss: 0.9888 - duration_loss: 0.1035 - val_loss: 10.3970 - val_pitch_loss: 8.5589 - val_duration_loss: 1.8371\n",
      "Epoch 27/100\n",
      "23024/23024 [==============================] - 84s 4ms/step - loss: 1.0417 - pitch_loss: 0.9442 - duration_loss: 0.0977 - val_loss: 10.8829 - val_pitch_loss: 8.8304 - val_duration_loss: 2.0515\n",
      "Epoch 28/100\n",
      "23024/23024 [==============================] - 83s 4ms/step - loss: 1.0030 - pitch_loss: 0.9088 - duration_loss: 0.0947 - val_loss: 10.8980 - val_pitch_loss: 8.9043 - val_duration_loss: 1.9928\n",
      "Epoch 29/100\n",
      "23024/23024 [==============================] - 80s 3ms/step - loss: 0.9809 - pitch_loss: 0.8890 - duration_loss: 0.0919 - val_loss: 11.1786 - val_pitch_loss: 9.1068 - val_duration_loss: 2.0708\n",
      "Epoch 30/100\n",
      "23024/23024 [==============================] - 79s 3ms/step - loss: 0.9482 - pitch_loss: 0.8600 - duration_loss: 0.0884 - val_loss: 11.0361 - val_pitch_loss: 8.9717 - val_duration_loss: 2.0637\n",
      "Epoch 31/100\n",
      "23024/23024 [==============================] - 79s 3ms/step - loss: 0.9113 - pitch_loss: 0.8247 - duration_loss: 0.0866 - val_loss: 11.3760 - val_pitch_loss: 9.2977 - val_duration_loss: 2.0776\n",
      "Epoch 32/100\n",
      "23024/23024 [==============================] - 80s 3ms/step - loss: 0.8794 - pitch_loss: 0.7966 - duration_loss: 0.0825 - val_loss: 11.4486 - val_pitch_loss: 9.3359 - val_duration_loss: 2.1117\n",
      "Epoch 33/100\n",
      "23024/23024 [==============================] - 84s 4ms/step - loss: 0.8647 - pitch_loss: 0.7837 - duration_loss: 0.0808 - val_loss: 11.3735 - val_pitch_loss: 9.3298 - val_duration_loss: 2.0427\n",
      "Epoch 34/100\n",
      "23024/23024 [==============================] - 81s 4ms/step - loss: 0.8390 - pitch_loss: 0.7587 - duration_loss: 0.0808 - val_loss: 11.5249 - val_pitch_loss: 9.3485 - val_duration_loss: 2.1760\n",
      "Epoch 35/100\n",
      "23024/23024 [==============================] - 82s 4ms/step - loss: 0.8304 - pitch_loss: 0.7508 - duration_loss: 0.0798 - val_loss: 11.4451 - val_pitch_loss: 9.2725 - val_duration_loss: 2.1722\n",
      "Epoch 36/100\n",
      "23024/23024 [==============================] - 79s 3ms/step - loss: 0.8082 - pitch_loss: 0.7333 - duration_loss: 0.0746 - val_loss: 11.6078 - val_pitch_loss: 9.4903 - val_duration_loss: 2.1170\n",
      "Epoch 37/100\n",
      "23024/23024 [==============================] - 79s 3ms/step - loss: 0.7784 - pitch_loss: 0.7084 - duration_loss: 0.0697 - val_loss: 11.9124 - val_pitch_loss: 9.6465 - val_duration_loss: 2.2649\n",
      "Epoch 38/100\n",
      "23024/23024 [==============================] - 81s 4ms/step - loss: 0.7740 - pitch_loss: 0.6997 - duration_loss: 0.0742 - val_loss: 11.7451 - val_pitch_loss: 9.5307 - val_duration_loss: 2.2134\n",
      "Epoch 39/100\n",
      "23024/23024 [==============================] - 81s 4ms/step - loss: 0.7635 - pitch_loss: 0.6883 - duration_loss: 0.0751 - val_loss: 11.9671 - val_pitch_loss: 9.6911 - val_duration_loss: 2.2752\n",
      "Epoch 40/100\n",
      "23024/23024 [==============================] - 81s 4ms/step - loss: 0.7521 - pitch_loss: 0.6803 - duration_loss: 0.0717 - val_loss: 12.1785 - val_pitch_loss: 9.7562 - val_duration_loss: 2.4215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/100\n",
      "23024/23024 [==============================] - 80s 3ms/step - loss: 0.7350 - pitch_loss: 0.6641 - duration_loss: 0.0715 - val_loss: 12.1331 - val_pitch_loss: 9.8734 - val_duration_loss: 2.2586\n",
      "Epoch 42/100\n",
      "23024/23024 [==============================] - 79s 3ms/step - loss: 0.7276 - pitch_loss: 0.6584 - duration_loss: 0.0689 - val_loss: 12.1485 - val_pitch_loss: 9.7724 - val_duration_loss: 2.3751\n",
      "Epoch 43/100\n",
      "23024/23024 [==============================] - 82s 4ms/step - loss: 0.7131 - pitch_loss: 0.6472 - duration_loss: 0.0659 - val_loss: 12.1085 - val_pitch_loss: 9.7635 - val_duration_loss: 2.3439\n",
      "Epoch 44/100\n",
      "23024/23024 [==============================] - 81s 4ms/step - loss: 0.7088 - pitch_loss: 0.6403 - duration_loss: 0.0682 - val_loss: 11.9166 - val_pitch_loss: 9.4579 - val_duration_loss: 2.4579\n",
      "Epoch 45/100\n",
      "23024/23024 [==============================] - 80s 3ms/step - loss: 0.6934 - pitch_loss: 0.6269 - duration_loss: 0.0662 - val_loss: 12.1166 - val_pitch_loss: 9.7291 - val_duration_loss: 2.3867\n",
      "Epoch 46/100\n",
      "23024/23024 [==============================] - 85s 4ms/step - loss: 0.6940 - pitch_loss: 0.6259 - duration_loss: 0.0681 - val_loss: 12.2229 - val_pitch_loss: 9.9023 - val_duration_loss: 2.3194\n",
      "Epoch 47/100\n",
      "23024/23024 [==============================] - 83s 4ms/step - loss: 0.6856 - pitch_loss: 0.6194 - duration_loss: 0.0665 - val_loss: 12.3706 - val_pitch_loss: 9.8073 - val_duration_loss: 2.5622\n",
      "Epoch 48/100\n",
      "23024/23024 [==============================] - 79s 3ms/step - loss: 0.6672 - pitch_loss: 0.6050 - duration_loss: 0.0624 - val_loss: 12.3791 - val_pitch_loss: 9.9293 - val_duration_loss: 2.4485\n",
      "Epoch 49/100\n",
      "23024/23024 [==============================] - 79s 3ms/step - loss: 0.6743 - pitch_loss: 0.6083 - duration_loss: 0.0662 - val_loss: 12.4179 - val_pitch_loss: 9.8050 - val_duration_loss: 2.6120\n",
      "Epoch 50/100\n",
      "23024/23024 [==============================] - 79s 3ms/step - loss: 0.6561 - pitch_loss: 0.5879 - duration_loss: 0.0679 - val_loss: 12.3615 - val_pitch_loss: 9.8066 - val_duration_loss: 2.5540\n",
      "Epoch 51/100\n",
      "23024/23024 [==============================] - 81s 4ms/step - loss: 0.6565 - pitch_loss: 0.5918 - duration_loss: 0.0648 - val_loss: 12.2515 - val_pitch_loss: 9.6990 - val_duration_loss: 2.5517\n",
      "Epoch 52/100\n",
      "23024/23024 [==============================] - 82s 4ms/step - loss: 0.6537 - pitch_loss: 0.5874 - duration_loss: 0.0663 - val_loss: 12.4422 - val_pitch_loss: 9.8674 - val_duration_loss: 2.5739\n",
      "Epoch 53/100\n",
      "23024/23024 [==============================] - 81s 4ms/step - loss: 0.6533 - pitch_loss: 0.5823 - duration_loss: 0.0708 - val_loss: 12.5246 - val_pitch_loss: 9.9316 - val_duration_loss: 2.5921\n",
      "Epoch 54/100\n",
      "23024/23024 [==============================] - 81s 4ms/step - loss: 0.6456 - pitch_loss: 0.5819 - duration_loss: 0.0641 - val_loss: 12.3482 - val_pitch_loss: 9.8455 - val_duration_loss: 2.5023\n",
      "Epoch 55/100\n",
      "23024/23024 [==============================] - 81s 4ms/step - loss: 0.6569 - pitch_loss: 0.5882 - duration_loss: 0.0684 - val_loss: 12.3593 - val_pitch_loss: 9.9348 - val_duration_loss: 2.4237\n",
      "Epoch 56/100\n",
      "23024/23024 [==============================] - 82s 4ms/step - loss: 0.6483 - pitch_loss: 0.5815 - duration_loss: 0.0666 - val_loss: 12.4450 - val_pitch_loss: 9.9079 - val_duration_loss: 2.5364\n",
      "Epoch 57/100\n",
      "23024/23024 [==============================] - 81s 4ms/step - loss: 0.6490 - pitch_loss: 0.5809 - duration_loss: 0.0683 - val_loss: 12.4260 - val_pitch_loss: 9.8799 - val_duration_loss: 2.5450\n",
      "Epoch 58/100\n",
      "23024/23024 [==============================] - 82s 4ms/step - loss: 0.6520 - pitch_loss: 0.5843 - duration_loss: 0.0689 - val_loss: 12.5130 - val_pitch_loss: 9.9593 - val_duration_loss: 2.5529\n",
      "Epoch 59/100\n",
      "23024/23024 [==============================] - 82s 4ms/step - loss: 0.6390 - pitch_loss: 0.5728 - duration_loss: 0.0660 - val_loss: 12.7036 - val_pitch_loss: 9.9753 - val_duration_loss: 2.7275\n",
      "Epoch 60/100\n",
      "23024/23024 [==============================] - 81s 4ms/step - loss: 0.6242 - pitch_loss: 0.5583 - duration_loss: 0.0657 - val_loss: 12.6224 - val_pitch_loss: 9.9241 - val_duration_loss: 2.6973\n",
      "Epoch 61/100\n",
      "23024/23024 [==============================] - 80s 3ms/step - loss: 0.6287 - pitch_loss: 0.5653 - duration_loss: 0.0633 - val_loss: 12.5981 - val_pitch_loss: 10.0636 - val_duration_loss: 2.5341\n",
      "Epoch 62/100\n",
      "23024/23024 [==============================] - 78s 3ms/step - loss: 0.6337 - pitch_loss: 0.5671 - duration_loss: 0.0666 - val_loss: 12.6756 - val_pitch_loss: 10.0455 - val_duration_loss: 2.6287\n",
      "Epoch 63/100\n",
      "23024/23024 [==============================] - 82s 4ms/step - loss: 0.6300 - pitch_loss: 0.5667 - duration_loss: 0.0635 - val_loss: 12.4168 - val_pitch_loss: 9.8812 - val_duration_loss: 2.5348\n",
      "Epoch 64/100\n",
      "23024/23024 [==============================] - 82s 4ms/step - loss: 0.6295 - pitch_loss: 0.5677 - duration_loss: 0.0617 - val_loss: 12.7983 - val_pitch_loss: 10.0445 - val_duration_loss: 2.7526\n",
      "Epoch 65/100\n",
      "23024/23024 [==============================] - 84s 4ms/step - loss: 0.6280 - pitch_loss: 0.5624 - duration_loss: 0.0652 - val_loss: 12.7227 - val_pitch_loss: 10.0053 - val_duration_loss: 2.7167\n",
      "Epoch 66/100\n",
      "23024/23024 [==============================] - 79s 3ms/step - loss: 0.6365 - pitch_loss: 0.5669 - duration_loss: 0.0697 - val_loss: 12.4613 - val_pitch_loss: 9.7673 - val_duration_loss: 2.6935\n",
      "Epoch 67/100\n",
      "23024/23024 [==============================] - 79s 3ms/step - loss: 0.6253 - pitch_loss: 0.5554 - duration_loss: 0.0698 - val_loss: 12.4526 - val_pitch_loss: 9.7082 - val_duration_loss: 2.7433\n",
      "Epoch 68/100\n",
      "23024/23024 [==============================] - 79s 3ms/step - loss: 0.6199 - pitch_loss: 0.5525 - duration_loss: 0.0671 - val_loss: 12.6968 - val_pitch_loss: 9.9644 - val_duration_loss: 2.7317\n",
      "Epoch 69/100\n",
      "23024/23024 [==============================] - 84s 4ms/step - loss: 0.6250 - pitch_loss: 0.5556 - duration_loss: 0.0694 - val_loss: 12.7768 - val_pitch_loss: 10.1742 - val_duration_loss: 2.6015\n",
      "Epoch 70/100\n",
      "23024/23024 [==============================] - 85s 4ms/step - loss: 0.6316 - pitch_loss: 0.5635 - duration_loss: 0.0681 - val_loss: 12.3514 - val_pitch_loss: 9.9319 - val_duration_loss: 2.4186\n",
      "Epoch 71/100\n",
      "23024/23024 [==============================] - 79s 3ms/step - loss: 0.6272 - pitch_loss: 0.5591 - duration_loss: 0.0683 - val_loss: 12.5691 - val_pitch_loss: 9.9994 - val_duration_loss: 2.5688\n",
      "Epoch 72/100\n",
      "23024/23024 [==============================] - 78s 3ms/step - loss: 0.6204 - pitch_loss: 0.5545 - duration_loss: 0.0658 - val_loss: 12.3088 - val_pitch_loss: 9.7882 - val_duration_loss: 2.5195\n",
      "Epoch 73/100\n",
      "23024/23024 [==============================] - 80s 3ms/step - loss: 0.6226 - pitch_loss: 0.5533 - duration_loss: 0.0693 - val_loss: 12.6289 - val_pitch_loss: 9.9010 - val_duration_loss: 2.7273\n",
      "Epoch 74/100\n",
      "23024/23024 [==============================] - 80s 3ms/step - loss: 0.6279 - pitch_loss: 0.5543 - duration_loss: 0.0734 - val_loss: 12.7192 - val_pitch_loss: 10.0879 - val_duration_loss: 2.6312\n",
      "Epoch 75/100\n",
      "23024/23024 [==============================] - 80s 3ms/step - loss: 0.6162 - pitch_loss: 0.5458 - duration_loss: 0.0702 - val_loss: 12.2128 - val_pitch_loss: 9.8010 - val_duration_loss: 2.4114\n",
      "Epoch 76/100\n",
      "23024/23024 [==============================] - 79s 3ms/step - loss: 0.6176 - pitch_loss: 0.5495 - duration_loss: 0.0691 - val_loss: 12.5932 - val_pitch_loss: 10.0145 - val_duration_loss: 2.5785\n",
      "Epoch 77/100\n",
      "23024/23024 [==============================] - 78s 3ms/step - loss: 0.6278 - pitch_loss: 0.5571 - duration_loss: 0.0705 - val_loss: 12.4844 - val_pitch_loss: 10.0029 - val_duration_loss: 2.4815\n",
      "Epoch 78/100\n",
      "23024/23024 [==============================] - 78s 3ms/step - loss: 0.6282 - pitch_loss: 0.5580 - duration_loss: 0.0703 - val_loss: 12.5076 - val_pitch_loss: 9.9096 - val_duration_loss: 2.5976\n",
      "Epoch 79/100\n",
      "23024/23024 [==============================] - 78s 3ms/step - loss: 0.6381 - pitch_loss: 0.5662 - duration_loss: 0.0718 - val_loss: 12.4623 - val_pitch_loss: 9.8322 - val_duration_loss: 2.6291\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23024/23024 [==============================] - 78s 3ms/step - loss: 0.6442 - pitch_loss: 0.5691 - duration_loss: 0.0748 - val_loss: 12.6049 - val_pitch_loss: 9.9926 - val_duration_loss: 2.6113\n",
      "Epoch 81/100\n",
      "23024/23024 [==============================] - 81s 4ms/step - loss: 0.6342 - pitch_loss: 0.5639 - duration_loss: 0.0710 - val_loss: 12.4919 - val_pitch_loss: 10.0079 - val_duration_loss: 2.4835\n",
      "Epoch 82/100\n",
      "23024/23024 [==============================] - 81s 4ms/step - loss: 0.6410 - pitch_loss: 0.5675 - duration_loss: 0.0741 - val_loss: 12.4804 - val_pitch_loss: 9.9565 - val_duration_loss: 2.5225\n",
      "Epoch 83/100\n",
      "23024/23024 [==============================] - 80s 3ms/step - loss: 0.6500 - pitch_loss: 0.5735 - duration_loss: 0.0764 - val_loss: 12.4669 - val_pitch_loss: 9.9583 - val_duration_loss: 2.5078\n",
      "Epoch 84/100\n",
      "23024/23024 [==============================] - 83s 4ms/step - loss: 0.6438 - pitch_loss: 0.5718 - duration_loss: 0.0718 - val_loss: 12.4388 - val_pitch_loss: 9.8814 - val_duration_loss: 2.5564\n",
      "Epoch 85/100\n",
      "23024/23024 [==============================] - 84s 4ms/step - loss: 0.6475 - pitch_loss: 0.5727 - duration_loss: 0.0751 - val_loss: 12.9421 - val_pitch_loss: 10.2385 - val_duration_loss: 2.7023\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1534cedef28>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_folder = os.path.join(run_folder, 'weights')\n",
    "\n",
    "checkpoint1 = ModelCheckpoint(\n",
    "    os.path.join(weights_folder, \"weights-improvement-{epoch:02d}-{loss:.4f}-bigger.h5\"),\n",
    "    monitor='loss',\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "checkpoint2 = ModelCheckpoint(\n",
    "    os.path.join(weights_folder, \"weights.h5\"),\n",
    "    monitor='loss',\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='loss'\n",
    "    , restore_best_weights=True\n",
    "    , patience = 10\n",
    ")\n",
    "\n",
    "\n",
    "callbacks_list = [\n",
    "    checkpoint1\n",
    "    , checkpoint2\n",
    "    , early_stopping\n",
    " ]\n",
    "\n",
    "model.save_weights(os.path.join(weights_folder, \"weights.h5\"))\n",
    "model.fit(network_input, network_output\n",
    "          , epochs=100, batch_size=32 # 200 epochs\n",
    "          , validation_split = 0.2\n",
    "          , callbacks=callbacks_list\n",
    "          , shuffle=True\n",
    "         )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
